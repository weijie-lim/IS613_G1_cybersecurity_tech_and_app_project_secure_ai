# IS613_G1_cybersecurity_tech_and_app_project_secure_ai
This is a course work project specifically looking at what are one of the ways AI models can be attacked how we are able to secure these models.

Credit to the following authors for their contribution towards securing AI:
Adverserial Attacks on MNIST Data Set https://github.com/MadryLab/mnist_challenge 
